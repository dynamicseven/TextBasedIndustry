{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-Based Industry Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "os.chdir(\"/Users/hanyi.wang/Documents/Projects/Text-based Correlation Model/Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **First we examine the data with the index file:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>Comname</th>\n",
       "      <th>File_Type</th>\n",
       "      <th>File_Date</th>\n",
       "      <th>txt_path</th>\n",
       "      <th>html_path</th>\n",
       "      <th>txt_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>1000298</td>\n",
       "      <td>IMPAC MORTGAGE HOLDINGS INC</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>edgar/data/1000298/0001558370-17-001542.txt</td>\n",
       "      <td>edgar/data/1000298/0001558370-17-001542-index....</td>\n",
       "      <td>10002980001558370-17-001542.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>1000623</td>\n",
       "      <td>SCHWEITZER MAUDUIT INTERNATIONAL INC</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2017-02-24</td>\n",
       "      <td>edgar/data/1000623/0001000623-17-000036.txt</td>\n",
       "      <td>edgar/data/1000623/0001000623-17-000036-index....</td>\n",
       "      <td>10006230001000623-17-000036.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>1000683</td>\n",
       "      <td>BLONDER TONGUE LABORATORIES INC</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>edgar/data/1000683/0001144204-17-017902.txt</td>\n",
       "      <td>edgar/data/1000683/0001144204-17-017902-index....</td>\n",
       "      <td>10006830001144204-17-017902.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1000694</td>\n",
       "      <td>NOVAVAX INC</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>edgar/data/1000694/0001144204-17-011334.txt</td>\n",
       "      <td>edgar/data/1000694/0001144204-17-011334-index....</td>\n",
       "      <td>10006940001144204-17-011334.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>1000697</td>\n",
       "      <td>WATERS CORP /DE/</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2017-02-24</td>\n",
       "      <td>edgar/data/1000697/0001193125-17-056239.txt</td>\n",
       "      <td>edgar/data/1000697/0001193125-17-056239-index....</td>\n",
       "      <td>10006970001193125-17-056239.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CIK                               Comname File_Type   File_Date  \\\n",
       "631  1000298           IMPAC MORTGAGE HOLDINGS INC      10-K  2017-03-09   \n",
       "652  1000623  SCHWEITZER MAUDUIT INTERNATIONAL INC      10-K  2017-02-24   \n",
       "681  1000683       BLONDER TONGUE LABORATORIES INC      10-K  2017-03-31   \n",
       "686  1000694                           NOVAVAX INC      10-K  2017-02-27   \n",
       "708  1000697                      WATERS CORP /DE/      10-K  2017-02-24   \n",
       "\n",
       "                                        txt_path  \\\n",
       "631  edgar/data/1000298/0001558370-17-001542.txt   \n",
       "652  edgar/data/1000623/0001000623-17-000036.txt   \n",
       "681  edgar/data/1000683/0001144204-17-017902.txt   \n",
       "686  edgar/data/1000694/0001144204-17-011334.txt   \n",
       "708  edgar/data/1000697/0001193125-17-056239.txt   \n",
       "\n",
       "                                             html_path  \\\n",
       "631  edgar/data/1000298/0001558370-17-001542-index....   \n",
       "652  edgar/data/1000623/0001000623-17-000036-index....   \n",
       "681  edgar/data/1000683/0001144204-17-017902-index....   \n",
       "686  edgar/data/1000694/0001144204-17-011334-index....   \n",
       "708  edgar/data/1000697/0001193125-17-056239-index....   \n",
       "\n",
       "                            txt_name  \n",
       "631  10002980001558370-17-001542.txt  \n",
       "652  10006230001000623-17-000036.txt  \n",
       "681  10006830001144204-17-017902.txt  \n",
       "686  10006940001144204-17-011334.txt  \n",
       "708  10006970001193125-17-056239.txt  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('index_file.dat', 'rb') as index:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    data_index = pickle.load(index)\n",
    "\n",
    "with open('Business Description.dat', 'rb') as d:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    data_businessD = pickle.load(d)\n",
    "    \n",
    "data_index.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "data_index = data_index[data_index['txt_path'].notna()]\n",
    "print(data_index['File_Date'].dtypes)\n",
    "data_index['File_Date'] = pd.to_datetime(data_index['File_Date'],format = '%Y-%m-%d')\n",
    "data_index['year'] = data_index['File_Date'].dt.year\n",
    "\n",
    "#seperate years individually\n",
    "data_2016 = data_index[data_index['year']==2016]\n",
    "data_2017 = data_index[data_index['year']==2017]\n",
    "data_2018 = data_index[data_index['year']==2018]\n",
    "data_2019 = data_index[data_index['year']==2019]\n",
    "\n",
    "data = data_2018 # change according to year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2185 entries, 93 to 197782\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   CIK        2185 non-null   int64         \n",
      " 1   Comname    2185 non-null   object        \n",
      " 2   File_Type  2185 non-null   object        \n",
      " 3   File_Date  2185 non-null   datetime64[ns]\n",
      " 4   txt_path   2185 non-null   object        \n",
      " 5   html_path  2185 non-null   object        \n",
      " 6   txt_name   2185 non-null   object        \n",
      " 7   year       2185 non-null   int64         \n",
      "dtypes: datetime64[ns](1), int64(2), object(5)\n",
      "memory usage: 153.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIK</th>\n",
       "      <th>Comname</th>\n",
       "      <th>File_Type</th>\n",
       "      <th>File_Date</th>\n",
       "      <th>txt_path</th>\n",
       "      <th>html_path</th>\n",
       "      <th>txt_name</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>1000298</td>\n",
       "      <td>IMPAC MORTGAGE HOLDINGS INC</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>edgar/data/1000298/0001558370-17-001542.txt</td>\n",
       "      <td>edgar/data/1000298/0001558370-17-001542-index....</td>\n",
       "      <td>10002980001558370-17-001542.txt</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>1000623</td>\n",
       "      <td>SCHWEITZER MAUDUIT INTERNATIONAL INC</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2017-02-24</td>\n",
       "      <td>edgar/data/1000623/0001000623-17-000036.txt</td>\n",
       "      <td>edgar/data/1000623/0001000623-17-000036-index....</td>\n",
       "      <td>10006230001000623-17-000036.txt</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>1000683</td>\n",
       "      <td>BLONDER TONGUE LABORATORIES INC</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>edgar/data/1000683/0001144204-17-017902.txt</td>\n",
       "      <td>edgar/data/1000683/0001144204-17-017902-index....</td>\n",
       "      <td>10006830001144204-17-017902.txt</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1000694</td>\n",
       "      <td>NOVAVAX INC</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2017-02-27</td>\n",
       "      <td>edgar/data/1000694/0001144204-17-011334.txt</td>\n",
       "      <td>edgar/data/1000694/0001144204-17-011334-index....</td>\n",
       "      <td>10006940001144204-17-011334.txt</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>1000697</td>\n",
       "      <td>WATERS CORP /DE/</td>\n",
       "      <td>10-K</td>\n",
       "      <td>2017-02-24</td>\n",
       "      <td>edgar/data/1000697/0001193125-17-056239.txt</td>\n",
       "      <td>edgar/data/1000697/0001193125-17-056239-index....</td>\n",
       "      <td>10006970001193125-17-056239.txt</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CIK                               Comname File_Type  File_Date  \\\n",
       "631  1000298           IMPAC MORTGAGE HOLDINGS INC      10-K 2017-03-09   \n",
       "652  1000623  SCHWEITZER MAUDUIT INTERNATIONAL INC      10-K 2017-02-24   \n",
       "681  1000683       BLONDER TONGUE LABORATORIES INC      10-K 2017-03-31   \n",
       "686  1000694                           NOVAVAX INC      10-K 2017-02-27   \n",
       "708  1000697                      WATERS CORP /DE/      10-K 2017-02-24   \n",
       "\n",
       "                                        txt_path  \\\n",
       "631  edgar/data/1000298/0001558370-17-001542.txt   \n",
       "652  edgar/data/1000623/0001000623-17-000036.txt   \n",
       "681  edgar/data/1000683/0001144204-17-017902.txt   \n",
       "686  edgar/data/1000694/0001144204-17-011334.txt   \n",
       "708  edgar/data/1000697/0001193125-17-056239.txt   \n",
       "\n",
       "                                             html_path  \\\n",
       "631  edgar/data/1000298/0001558370-17-001542-index....   \n",
       "652  edgar/data/1000623/0001000623-17-000036-index....   \n",
       "681  edgar/data/1000683/0001144204-17-017902-index....   \n",
       "686  edgar/data/1000694/0001144204-17-011334-index....   \n",
       "708  edgar/data/1000697/0001193125-17-056239-index....   \n",
       "\n",
       "                            txt_name  year  \n",
       "631  10002980001558370-17-001542.txt  2017  \n",
       "652  10006230001000623-17-000036.txt  2017  \n",
       "681  10006830001144204-17-017902.txt  2017  \n",
       "686  10006940001144204-17-011334.txt  2017  \n",
       "708  10006970001193125-17-056239.txt  2017  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2185"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_firm = data.count()[0]\n",
    "num_firm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now the Business Description Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ITEM 1. BUSINESS Overview We develop, manufacture and sell proprietary biological testing technologies and products with applications throughout the life sciences industries, including diagnostics, pharmaceutical and research. These industries depend on a broad range of tests, called assays, to perform diagnostic testing and conduct life science research. We have established a position in several segments of the life sciences industries by developing and delivering products that satisfy a variety of customer needs in specific market segments, including multiplexing, accuracy, precision, sensitivity, specificity, reduction of labor and ability to test for proteins and nucleic acids. These needs are addressed by our proprietary technologies. Multiplexing, the foundation of our Company, allows the end user in a laboratory to generate multiple laboratory results from a single sample with a single assay. This is important because our end user customers, which include laboratory professional'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_businessD['10339050001033905-18-000014.txt'][0:1000]\n",
    "#data_businessD[data_index.iat[i, 6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize BD and Select Noun(NN) and Propernoun(NNP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokens = nltk.word_tokenize(data_businessD['10339050001033905-18-000014.txt'][0:1000])\n",
    "import enchant\n",
    "\n",
    "all_noun = []\n",
    "all_propernoun = []\n",
    "\n",
    "for i in range(0,len(data)): #len(data_index)\n",
    "    tokens = nltk.word_tokenize(data_businessD[data.iat[i, 6]])\n",
    "    \n",
    "    #Using Enchant package to standerdize our text input\n",
    "    legal_dict = enchant.Dict(\"en_US\")\n",
    "    tokens= [word for word in tokens if (word.isalpha()) & (legal_dict.check(word))]\n",
    "    \n",
    "    #nltk Part Of Speech Package to select NN and NNP.\n",
    "    pos = nltk.pos_tag(tokens)\n",
    "    word_list = set([word for word in pos if (word[1] == 'NN') | (word[1] == 'NNP')])\n",
    "    dic_noun = [s[0] for s in word_list if s[1] == 'NN']\n",
    "    all_noun.append(dic_noun)\n",
    "    dic_propernoun = [s[0] for s in word_list if s[1] == 'NNP']\n",
    "    all_propernoun.append(dic_propernoun)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[See reference for POS taggings](https://www.guru99.com/pos-tagging-chunking-nltk.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_noun_dic = defaultdict(int)\n",
    "all_propernoun_dic = defaultdict(int)\n",
    "# Bring 'NN' into our dictionary\n",
    "for i in range(0,len(data)):\n",
    "    for j in range(len(all_noun[i])):\n",
    "        all_noun_dic[all_noun[i][j]] += 1\n",
    "\n",
    "# Bring 'NNP' into our dictionary\n",
    "for i in range(len(data)):\n",
    "    for j in range(len(all_propernoun[i])):\n",
    "        all_propernoun_dic[all_propernoun[i][j]] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ### Screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save NNPs that have 90%+ higher case ratio\n",
    "all_propernoun_selected_dic = {i:all_propernoun_dic[i] for i in all_propernoun_dic if all_propernoun_dic[i] / (all_propernoun_dic[i] + all_noun_dic[i.lower()]) > 0.9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only Text with less than 25% recurrence ratio to screen out common terms\n",
    "num = data.count()\n",
    "all_dic = {**all_noun_dic, **defaultdict(int,all_propernoun_selected_dic)}\n",
    "all_selected_word = [i for i in all_dic if (all_dic[i] / num[0] < 0.25) & (all_dic[i]) != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Token Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = []\n",
    "for i in range(len(data)):\n",
    "    vector = [(word in all_noun[i]) | (word in all_propernoun[i]) for word in all_selected_word]\n",
    "    matrix.append(vector)\n",
    "df = pd.DataFrame(matrix, index = data['Comname'].tolist(), columns = all_selected_word).replace({True:1, False:0})  \n",
    "df.to_pickle(\"./Mappings-2018.pkl\") #Write mappings to pickel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2185 entries, HENRY SCHEIN INC to WASHINGTON FEDERAL INC\n",
      "Columns: 17181 entries, track to Hermitage\n",
      "dtypes: int64(17181)\n",
      "memory usage: 286.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>mandate</th>\n",
       "      <th>shift</th>\n",
       "      <th>announcement</th>\n",
       "      <th>defendant</th>\n",
       "      <th>incurring</th>\n",
       "      <th>payroll</th>\n",
       "      <th>alternate</th>\n",
       "      <th>disproportionate</th>\n",
       "      <th>speculation</th>\n",
       "      <th>...</th>\n",
       "      <th>Bombshells</th>\n",
       "      <th>SEVILLE</th>\n",
       "      <th>Jaguars</th>\n",
       "      <th>ONYX</th>\n",
       "      <th>Excepting</th>\n",
       "      <th>SALOON</th>\n",
       "      <th>TOOTSIES</th>\n",
       "      <th>INTELSAT</th>\n",
       "      <th>Nettles</th>\n",
       "      <th>Hermitage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HENRY SCHEIN INC</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WATERS CORP /DE/</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SANGAMO THERAPEUTICS, INC</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TG THERAPEUTICS, INC.</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NORTHWEST PIPE CO</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 17181 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           track  mandate  shift  announcement  defendant  \\\n",
       "HENRY SCHEIN INC               1        1      1             1          1   \n",
       "WATERS CORP /DE/               0        0      0             0          0   \n",
       "SANGAMO THERAPEUTICS, INC      0        0      0             0          0   \n",
       "TG THERAPEUTICS, INC.          1        0      0             0          0   \n",
       "NORTHWEST PIPE CO              0        0      0             1          0   \n",
       "\n",
       "                           incurring  payroll  alternate  disproportionate  \\\n",
       "HENRY SCHEIN INC                   1        1          1                 1   \n",
       "WATERS CORP /DE/                   0        0          0                 0   \n",
       "SANGAMO THERAPEUTICS, INC          0        0          0                 0   \n",
       "TG THERAPEUTICS, INC.              0        0          0                 1   \n",
       "NORTHWEST PIPE CO                  0        0          1                 0   \n",
       "\n",
       "                           speculation  ...  Bombshells  SEVILLE  Jaguars  \\\n",
       "HENRY SCHEIN INC                     1  ...           0        0        0   \n",
       "WATERS CORP /DE/                     0  ...           0        0        0   \n",
       "SANGAMO THERAPEUTICS, INC            0  ...           0        0        0   \n",
       "TG THERAPEUTICS, INC.                0  ...           0        0        0   \n",
       "NORTHWEST PIPE CO                    1  ...           0        0        0   \n",
       "\n",
       "                           ONYX  Excepting  SALOON  TOOTSIES  INTELSAT  \\\n",
       "HENRY SCHEIN INC              0          0       0         0         0   \n",
       "WATERS CORP /DE/              0          0       0         0         0   \n",
       "SANGAMO THERAPEUTICS, INC     0          0       0         0         0   \n",
       "TG THERAPEUTICS, INC.         0          0       0         0         0   \n",
       "NORTHWEST PIPE CO             0          0       0         0         0   \n",
       "\n",
       "                           Nettles  Hermitage  \n",
       "HENRY SCHEIN INC                 0          0  \n",
       "WATERS CORP /DE/                 0          0  \n",
       "SANGAMO THERAPEUTICS, INC        0          0  \n",
       "TG THERAPEUTICS, INC.            0          0  \n",
       "NORTHWEST PIPE CO                0          0  \n",
       "\n",
       "[5 rows x 17181 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulls = df.isna().sum()/df.shape[0]\n",
    "df.info()\n",
    "df.head()\n",
    "# ap = df[df.loc[['POLARITYTE, INC.']]>0]\n",
    "# print(df.loc[['POLARITYTE, INC.']]>0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some normalization \n",
    "norm = np.linalg.norm(df, axis = 1)\n",
    "norm = norm.reshape(norm.shape[0],1)\n",
    "df_norm = df/norm[:, ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_matrix = []\n",
    "cor_matrix = np.matrix(df_norm).dot(np.matrix(df_norm).T)\n",
    "cor_df = pd.DataFrame(cor_matrix,index = data['Comname'].tolist(),columns = data['Comname'].tolist())\n",
    "cor_df.head()\n",
    "cor_df.to_pickle('2018_correlation.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fin_matrix = []\n",
    "# for i in range(len(df)):\n",
    "#     fin_vector = []\n",
    "#     for j in range(len(df)):\n",
    "#         dot = np.matrix(df.iloc[i]).dot(np.matrix(df.iloc[j]).T)\n",
    "#         leni = math.sqrt(np.matrix(df.iloc[i]).dot(np.matrix(df.iloc[i]).T))\n",
    "#         lenj = math.sqrt(np.matrix(df.iloc[j]).dot(np.matrix(df.iloc[j]).T))\n",
    "#         fin_vector.append(dot/(leni * lenj))\n",
    "#     fin_matrix.append(fin_vector)\n",
    "# fin_df = pd.DataFrame(fin_matrix, index = index['Comname'].tolist(), columns = index['Comname'].tolist())\n",
    "# din_df.to_pickle('2018.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
